{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "11Yd_VMwMzH9nrKFF1ouvsPlqAAP7Xf9Z",
      "authorship_tag": "ABX9TyMrgAbC7+n3VT5PxAOGS9vn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbittel/Coding_Challenge/blob/main/Section1_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install db-sqlite3\n",
        "!pip install flask pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mulKjo2hn14z",
        "outputId": "c3a46bb0-b44d-4a62-9e99-a0abac254fa3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: db-sqlite3 in /usr/local/lib/python3.10/dist-packages (0.0.1)\n",
            "Requirement already satisfied: db in /usr/local/lib/python3.10/dist-packages (from db-sqlite3) (0.1.1)\n",
            "Requirement already satisfied: antiorm in /usr/local/lib/python3.10/dist-packages (from db->db-sqlite3) (1.2.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (6.0.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (2.3.7)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import io\n",
        "import pandas as pd\n",
        "import sqlite3"
      ],
      "metadata": {
        "id": "3iIc_WHANblQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTNd7mvZ1k_O",
        "outputId": "d7653509-bca2-402e-90c7-85713880b47c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SQLite3 database"
      ],
      "metadata": {
        "id": "GRf9fjYQAA2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "database_path = '/content/drive/MyDrive/Data Science/Globant_tests'\n",
        "database_name = f'{database_path}/historical_data.db'"
      ],
      "metadata": {
        "id": "fb3jgvBiUbUa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SQLiteDataManager:\n",
        "    def __init__(self, db_name):\n",
        "        \"\"\"\n",
        "        Initialize the SQLiteDataManager with the given database name.\n",
        "\n",
        "        Args:\n",
        "            db_name (str): The name of the SQLite database.\n",
        "        \"\"\"\n",
        "        self.db_name = db_name\n",
        "\n",
        "    def save_dataframe_to_sqlite(self, table_name, df):\n",
        "        \"\"\"\n",
        "        Save a DataFrame to an SQLite table in the database.\n",
        "\n",
        "        Args:\n",
        "            table_name (str): The name of the table to save the DataFrame to.\n",
        "            df (pd.DataFrame): The DataFrame to be saved.\n",
        "        \"\"\"\n",
        "        conn = sqlite3.connect(self.db_name)\n",
        "        df.to_sql(table_name, conn, if_exists='append', index=False)\n",
        "        conn.close()\n",
        "\n",
        "    def query_data_from_sqlite(self, table_name, sql_query):\n",
        "        \"\"\"\n",
        "        Query data from an SQLite table using a custom SQL query.\n",
        "\n",
        "        Args:\n",
        "            table_name (str): The name of the table to query.\n",
        "            sql_query (str): The SQL query to execute.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: The result of the query as a DataFrame.\n",
        "        \"\"\"\n",
        "        conn = sqlite3.connect(self.db_name)\n",
        "        result = pd.read_sql_query(sql_query, conn)\n",
        "        conn.close()\n",
        "        return result\n",
        "\n",
        "    def clear_database(self):\n",
        "        \"\"\"\n",
        "        Query and Delete all tables from an SQLite database using SQL query.\n",
        "\n",
        "        Returns:\n",
        "            Exception: The error message.\n",
        "        \"\"\"\n",
        "        try:\n",
        "          db_connection = sqlite3.connect(database_name)\n",
        "          cursor = db_connection.cursor()\n",
        "          cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
        "          tables = cursor.fetchall()\n",
        "          for table in tables:\n",
        "              cursor.execute(f\"DROP TABLE {table[0]}\")\n",
        "          db_connection.commit()\n",
        "          db_connection.close()\n",
        "        except Exception as e:\n",
        "          return str(e)"
      ],
      "metadata": {
        "id": "Jr9HxxMKwkb3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bi7Pc-8ab_UG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Flask / pyNgrok API endpoints"
      ],
      "metadata": {
        "id": "GrKNFG26AKAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DEfine Flask application interface\n",
        "app = Flask(__name__)\n",
        "\n",
        "def run_flask_app():\n",
        "    app.run()\n"
      ],
      "metadata": {
        "id": "ZU1nUtIbqbUo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@app.route('/hello', methods=['GET'])\n",
        "def hello():\n",
        "    return jsonify(message=\"Hello from your API!\")\n"
      ],
      "metadata": {
        "id": "iRu-ChBnyLs-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.route('/historical_data_csv', methods=['POST'])\n",
        "def historical_data_csv():\n",
        "    \"\"\"\n",
        "    Endpoint that receives a list of three CSV files and saves them to a SQLite3 database.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        files = request.files.getlist('files')\n",
        "\n",
        "        if len(files) != 3:\n",
        "            return jsonify(error=\"Exactly three files are required\")\n",
        "\n",
        "        # Initialize the access to data\n",
        "        db_manager = SQLiteDataManager(database_name)\n",
        "\n",
        "        # Clear the SQLite database before processing\n",
        "        db_manager.clear_database()\n",
        "        processed_data = []\n",
        "\n",
        "        for file in files:\n",
        "            if file.filename == '':\n",
        "                return jsonify(error=\"One of the files is empty\")\n",
        "            elif file.filename == 'departments.csv':\n",
        "              column_names = ['dept_id', 'dept_name']\n",
        "            elif file.filename == 'jobs.csv':\n",
        "              column_names = ['job_id', 'job_name']\n",
        "            elif file.filename == 'hired_employees.csv':\n",
        "              column_names = ['empl_id', 'empl_name', 'hired', 'dept_id', 'job_id']\n",
        "\n",
        "            # Read the CSV file into a pandas DataFrame\n",
        "            csv_data = file.read().decode('utf-8')\n",
        "            df = pd.read_csv(io.StringIO(csv_data), names=column_names)   # pd.compat.StringIO(csv_data)\n",
        "\n",
        "            # Get table name from the filename without extension\n",
        "            table_name = file.filename.split('.')[0]\n",
        "\n",
        "            batch_size = 1000\n",
        "            num_batches = len(df) // batch_size + 1\n",
        "\n",
        "            for batch_num in range(num_batches):\n",
        "                batch_df = df.iloc[batch_num * batch_size : (batch_num + 1) * batch_size]\n",
        "                # Process the batch - example: convert to JSON format\n",
        "                processed_batch = batch_df.to_json(orient='records')\n",
        "                # Process the batch - save to SQLite3 format\n",
        "                db_manager.save_dataframe_to_sqlite(table_name, batch_df)\n",
        "\n",
        "                processed_data.append(processed_batch)\n",
        "\n",
        "            print(jsonify(processed_data.append(\"Data successfully processed and saved\")))\n",
        "\n",
        "        return jsonify(processed_data)\n",
        "    except Exception as e:\n",
        "        return jsonify(error=str(e))\n"
      ],
      "metadata": {
        "id": "CozOywQ-ybg2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Run application and publish the endpoints"
      ],
      "metadata": {
        "id": "1CdF2eRIAeaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize the access to data\n",
        "    #db_manager = SQLiteDataManager(database_name)\n",
        "\n",
        "\n",
        "    # Start the Flask app in a separate thread\n",
        "    flask_thread = threading.Thread(target=run_flask_app)\n",
        "    flask_thread.start()\n",
        "\n",
        "    # Get the public URL using ngrok\n",
        "    public_url = ngrok.connect(addr='5000')\n",
        "    print(f'public_url: {public_url}     ---   copy this URL to the tests module \"public_url\" variable.')\n"
      ],
      "metadata": {
        "id": "KcqW4PpVyIjK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0bdb9dc-3c3d-4c5c-80c0-15eeed4ad4ff"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ngrok ...\r * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-08-18T05:02:41+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "public_url: NgrokTunnel: \"https://b653-35-237-3-228.ngrok.io\" -> \"http://localhost:5000\"     ---   copy this URL to the tests module \"public_url\" variable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v4xiXUQKyDfk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}